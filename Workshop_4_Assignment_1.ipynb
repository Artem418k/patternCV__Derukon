{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edadfacf-db1e-46b6-86f9-6d99a9efbe9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copyfile\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "# Определение путей к изображениям\n",
    "drive.mount('/content/drive')\n",
    "source_path = '/content/drive/My Drive/labsfile/PetImages'\n",
    "source_path_dogs = '/content/drive/My Drive/labsfile/PetImages/Dog'\n",
    "source_path_cats = '/content/drive/My Drive/labsfile/PetImages/Cat'\n",
    "# Вывод количества изображений\n",
    "print(f\"Всего изображений собак: {len(os.listdir(source_path_dogs))}\")\n",
    "print(f\"Всего изображений кошек: {len(os.listdir(source_path_cats))}\")\n",
    "\n",
    "\n",
    "# Функция для создания каталогов для обучающего и тестового наборов\n",
    "def create_train_val_dirs(root_path):\n",
    "    training_cats_dir = os.path.join(root_path, 'training', 'cats')\n",
    "    training_dogs_dir = os.path.join(root_path, 'training', 'dogs')\n",
    "    validation_cats_dir = os.path.join(root_path, 'validation', 'cats')\n",
    "    validation_dogs_dir = os.path.join(root_path, 'validation', 'dogs')\n",
    "\n",
    "    # Проверяем существование каталогов перед их созданием\n",
    "    if not os.path.exists(training_cats_dir):\n",
    "        os.makedirs(training_cats_dir, mode=0o755)\n",
    "    if not os.path.exists(training_dogs_dir):\n",
    "        os.makedirs(training_dogs_dir, mode=0o755)\n",
    "    if not os.path.exists(validation_cats_dir):\n",
    "        os.makedirs(validation_cats_dir, mode=0o755)\n",
    "    if not os.path.exists(validation_dogs_dir):\n",
    "        os.makedirs(validation_dogs_dir, mode=0o755)\n",
    "\n",
    "root_dir = '/content/drive/My Drive/labsfile/PetImages'\n",
    "create_train_val_dirs(root_dir)\n",
    "\n",
    "# Тестирование функции create_train_val_dirs\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))\n",
    "\n",
    "# Функция для разделения данных на обучающий и тестовый наборы\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  files = []\n",
    "  for filename in os.listdir(SOURCE_DIR):\n",
    "    file = SOURCE_DIR + filename\n",
    "    if os.path.getsize(file) > 0:\n",
    "      files.append(filename)\n",
    "    else:\n",
    "      print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "  training_length = int(len(files) * SPLIT_SIZE)\n",
    "  shuffled_set = random.sample(files, len(files))\n",
    "  training_set = shuffled_set[0:training_length]\n",
    "  validation_set = shuffled_set[training_length:]\n",
    "\n",
    "  for filename in training_set:\n",
    "    this_file = SOURCE_DIR + filename\n",
    "    destination = TRAINING_DIR + filename\n",
    "    copyfile(this_file, destination)\n",
    "\n",
    "  for filename in validation_set:\n",
    "    this_file = SOURCE_DIR + filename\n",
    "    destination = VALIDATION_DIR + filename\n",
    "    copyfile(this_file, destination)\n",
    "\n",
    "\n",
    "# Определение путей\n",
    "CAT_SOURCE_DIR = \"/content/drive/My Drive/labsfile/PetImages/Cat/\"\n",
    "DOG_SOURCE_DIR = \"/content/drive/My Drive/labsfile/PetImages/Dog/\"\n",
    "\n",
    "TRAINING_DIR = \"/content/drive/My Drive/labsfile/PetImages/training/\"\n",
    "VALIDATION_DIR = \"/content/drive/My Drive/labsfile/PetImages/validation/\"\n",
    "\n",
    "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
    "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
    "\n",
    "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
    "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
    "\n",
    "# Очистка каталогов в случае, если вы запускаете эту ячейку несколько раз\n",
    "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Определение доли изображений, используемых для обучения\n",
    "split_size = .9\n",
    "\n",
    "# Запуск функции\n",
    "# ПРИМЕЧАНИЕ: Должны быть напечатаны сообщения о нулевой длине изображений\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
    "\n",
    "# Проверка, что количество изображений соответствует ожидаемому результату\n",
    "print(f\"\\n\\nВсего изображений кошек: {len(os.listdir(CAT_SOURCE_DIR))}\")\n",
    "print(f\"Всего изображений собак: {len(os.listdir(DOG_SOURCE_DIR))}\\n\")\n",
    "\n",
    "# Обучающие и валидационные наборы\n",
    "print(f\"Изображений кошек для обучения: {len(os.listdir(TRAINING_CATS_DIR))}\")\n",
    "print(f\"Изображений собак для обучения: {len(os.listdir(TRAINING_DOGS_DIR))}\")\n",
    "print(f\"Изображений кошек для валидации: {len(os.listdir(VALIDATION_CATS_DIR))}\")\n",
    "print(f\"Изображений собак для валидации: {len(os.listdir(VALIDATION_DOGS_DIR))}\")\n",
    "\n",
    "# Функция для создания генераторов обучающих и валидационных данных\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "\n",
    " # Создание экземпляра класса ImageDataGenerator (не забудьте установить аргумент rescale)\n",
    "  train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "  # Передача соответствующих аргументов в метод flow_from_directory\n",
    "  train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                      batch_size=100,\n",
    "                                                      class_mode='binary',\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    "  # Создание экземпляра класса ImageDataGenerator (не забудьте установить аргумент rescale)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "  # Передача соответствующих аргументов в метод flow_from_directory\n",
    "  validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                                batch_size=100,\n",
    "                                                                class_mode='binary',\n",
    "                                                                target_size=(150, 150))\n",
    "  return train_generator, validation_generator\n",
    "\n",
    "# Тестирование генераторов\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)\n",
    "\n",
    "# Функция для создания модели\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Получение необученной модели\n",
    "model = create_model()\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator)\n",
    "\n",
    "# Визуализация результатов обучения\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01279be2-5275-4301-8921-44ef7ef1217d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
